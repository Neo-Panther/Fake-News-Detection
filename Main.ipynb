{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIAR Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.9.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: spacy==3.8.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.8.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: Keras==3.6.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: tensorflow==2.18.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk==3.9.1->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk==3.9.1->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk==3.9.1->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from nltk==3.9.1->-r requirements.txt (line 1)) (4.67.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (0.13.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.10/site-packages (from spacy==3.8.2->-r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (3.12.1)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in ./.venv/lib/python3.10/site-packages (from Keras==3.6.0->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (5.28.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.18.0->-r requirements.txt (line 5)) (0.45.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.8.2->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2->-r requirements.txt (line 2)) (2.27.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->-r requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->-r requirements.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->-r requirements.txt (line 5)) (3.1.3)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy==3.8.2->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy==3.8.2->-r requirements.txt (line 2)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.2->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich->Keras==3.6.0->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich->Keras==3.6.0->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.2->-r requirements.txt (line 2)) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.2->-r requirements.txt (line 2)) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->spacy==3.8.2->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.8.2->-r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->Keras==3.6.0->-r requirements.txt (line 4)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 00:12:52.322607: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 00:12:52.483717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732214572.542549   19349 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732214572.562132   19349 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 00:12:52.737256: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/destrox/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow_utils import get_info\n",
    "# get_info.tf_info()\n",
    "# get_info.gpu_info()\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# get the GPU device name\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('Data/train.tsv', names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \"barely-true\", \"false\", \"half-true\", \"mostly-true\", \"pants-fire\", \"venue\"])\n",
    "test_data = pd.read_table('Data/test.tsv', names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \"barely-true\", \"false\", \"half-true\", \"mostly-true\", \"pants-fire\", \"venue\"])\n",
    "valid_data = pd.read_table('Data/valid.tsv', names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \"barely-true\", \"false\", \"half-true\", \"mostly-true\", \"pants-fire\", \"venue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           10240 non-null  object \n",
      " 1   label        10240 non-null  object \n",
      " 2   statement    10240 non-null  object \n",
      " 3   subject      10238 non-null  object \n",
      " 4   speaker      10238 non-null  object \n",
      " 5   job          7342 non-null   object \n",
      " 6   state        8030 non-null   object \n",
      " 7   party        10238 non-null  object \n",
      " 8   barely-true  10238 non-null  float64\n",
      " 9   false        10238 non-null  float64\n",
      " 10  half-true    10238 non-null  float64\n",
      " 11  mostly-true  10238 non-null  float64\n",
      " 12  pants-fire   10238 non-null  float64\n",
      " 13  venue        10138 non-null  object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "Testing Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1267 entries, 0 to 1266\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           1267 non-null   object\n",
      " 1   label        1267 non-null   object\n",
      " 2   statement    1267 non-null   object\n",
      " 3   subject      1267 non-null   object\n",
      " 4   speaker      1267 non-null   object\n",
      " 5   job          942 non-null    object\n",
      " 6   state        1005 non-null   object\n",
      " 7   party        1267 non-null   object\n",
      " 8   barely-true  1267 non-null   int64 \n",
      " 9   false        1267 non-null   int64 \n",
      " 10  half-true    1267 non-null   int64 \n",
      " 11  mostly-true  1267 non-null   int64 \n",
      " 12  pants-fire   1267 non-null   int64 \n",
      " 13  venue        1250 non-null   object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 138.7+ KB\n",
      "None\n",
      "Validation Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1284 entries, 0 to 1283\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           1284 non-null   object\n",
      " 1   label        1284 non-null   object\n",
      " 2   statement    1284 non-null   object\n",
      " 3   subject      1284 non-null   object\n",
      " 4   speaker      1284 non-null   object\n",
      " 5   job          939 non-null    object\n",
      " 6   state        1005 non-null   object\n",
      " 7   party        1284 non-null   object\n",
      " 8   barely-true  1284 non-null   int64 \n",
      " 9   false        1284 non-null   int64 \n",
      " 10  half-true    1284 non-null   int64 \n",
      " 11  mostly-true  1284 non-null   int64 \n",
      " 12  pants-fire   1284 non-null   int64 \n",
      " 13  venue        1272 non-null   object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 140.6+ KB\n",
      "None\n",
      "['false' 'half-true' 'mostly-true' 'true' 'barely-true' 'pants-fire']\n",
      "           id        label                                          statement  \\\n",
      "0   2635.json        false  Says the Annies List political group supports ...   \n",
      "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
      "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
      "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
      "\n",
      "                              subject         speaker                   job  \\\n",
      "0                            abortion    dwayne-bohac  State representative   \n",
      "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
      "2                      foreign-policy    barack-obama             President   \n",
      "3                         health-care    blog-posting                   NaN   \n",
      "4                        economy,jobs   charlie-crist                   NaN   \n",
      "\n",
      "      state       party  barely-true  false  half-true  mostly-true  \\\n",
      "0     Texas  republican          0.0    1.0        0.0          0.0   \n",
      "1  Virginia    democrat          0.0    0.0        1.0          1.0   \n",
      "2  Illinois    democrat         70.0   71.0      160.0        163.0   \n",
      "3       NaN        none          7.0   19.0        3.0          5.0   \n",
      "4   Florida    democrat         15.0    9.0       20.0         19.0   \n",
      "\n",
      "   pants-fire                venue  \n",
      "0         0.0             a mailer  \n",
      "1         0.0      a floor speech.  \n",
      "2         9.0               Denver  \n",
      "3        44.0       a news release  \n",
      "4         2.0  an interview on CNN  \n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Info:\")\n",
    "print(train_data.info())\n",
    "print(\"Testing Data Info:\")\n",
    "print(test_data.info())\n",
    "print(\"Validation Data Info:\")\n",
    "print(valid_data.info())\n",
    "print(train_data.label.unique())\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Categorical Data to Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on degree of truthfullness\n",
    "y_label_dict = {\"pants-fire\" : 0, \"false\" : 1, \"barely-true\" : 2, \"half-true\" : 3, \"mostly-true\" : 4, \"true\" : 5}\n",
    "\n",
    "train_data['output'] = train_data['label'].apply(lambda i: y_label_dict[i])\n",
    "valid_data['output'] = valid_data['label'].apply(lambda i: y_label_dict[i])\n",
    "test_data['output'] = test_data['label'].apply(lambda i: y_label_dict[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barack-obama': 0, 'donald-trump': 1, 'hillary-clinton': 2, 'mitt-romney': 3, 'scott-walker': 4, 'john-mccain': 5, 'rick-perry': 6, 'chain-email': 7, 'marco-rubio': 8, 'rick-scott': 9, 'ted-cruz': 10, 'bernie-s': 11, 'chris-christie': 12, 'facebook-posts': 13, 'charlie-crist': 14, 'newt-gingrich': 15, 'jeb-bush': 16, 'joe-biden': 17, 'blog-posting': 18, 'paul-ryan': 19, 'sarah-palin': 20, 'john-boehner': 21, 'michele-bachmann': 22, 'rick-santorum': 23, 'national-republican-congressional-committee': 24}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "speaker_id\n",
       "25    7295\n",
       "0      488\n",
       "1      273\n",
       "2      239\n",
       "3      176\n",
       "4      149\n",
       "5      148\n",
       "7      142\n",
       "6      142\n",
       "8      117\n",
       "9      115\n",
       "10      93\n",
       "11      88\n",
       "13      78\n",
       "12      78\n",
       "14      70\n",
       "15      69\n",
       "17      63\n",
       "16      63\n",
       "18      59\n",
       "19      56\n",
       "20      52\n",
       "21      49\n",
       "24      46\n",
       "22      46\n",
       "23      46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of top speakers to consider a parameter\n",
    "no_speaker = 25\n",
    "# based on the frequency of the label (only consider the top no_speaker speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_speakers = train_data['speaker'].value_counts().reset_index()[:no_speaker].to_dict()['speaker']\n",
    "frequent_speakers = dict((v, k) for k, v in frequent_speakers.items())\n",
    "print(frequent_speakers)\n",
    "\n",
    "def convert_speaker_to_num(speaker):\n",
    "  # speaker not in the top 20, assign it to the 21st category\n",
    "  other = no_speaker\n",
    "  if isinstance(speaker, str):\n",
    "    if speaker in frequent_speakers:\n",
    "      return frequent_speakers[speaker]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['speaker_id'] = train_data['speaker'].apply(convert_speaker_to_num)\n",
    "valid_data['speaker_id'] = valid_data['speaker'].apply(convert_speaker_to_num)\n",
    "test_data['speaker_id'] = test_data['speaker'].apply(convert_speaker_to_num)\n",
    "train_data['speaker_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'President': 0, 'U.S. Senator': 1, 'Governor': 2, 'President-Elect': 3, 'U.S. senator': 4, 'Presidential candidate': 5, 'Former governor': 6, 'U.S. Representative': 7, 'Milwaukee County Executive': 8, 'Senator': 9, 'State Senator': 10, 'U.S. representative': 11, 'U.S. House of Representatives': 12, 'Attorney': 13, 'Congressman': 14, 'Social media posting': 15, 'Governor of New Jersey': 16, 'Co-host on CNN\\'s \"Crossfire\"': 17, 'State Representative': 18, 'State representative': 19, 'U.S. Congressman': 20, 'Congresswoman': 21, 'Speaker of the House of Representatives': 22, 'State senator': 23, 'state representative': 24}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job_id\n",
       "25    6348\n",
       "0      492\n",
       "1      479\n",
       "2      391\n",
       "3      273\n",
       "4      263\n",
       "5      254\n",
       "6      176\n",
       "7      172\n",
       "8      149\n",
       "9      147\n",
       "10     108\n",
       "11     103\n",
       "12     102\n",
       "13      81\n",
       "14      80\n",
       "15      78\n",
       "16      78\n",
       "17      73\n",
       "18      72\n",
       "19      66\n",
       "20      63\n",
       "22      50\n",
       "21      50\n",
       "23      48\n",
       "24      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of top jobs to consider a parameter\n",
    "no_jobs = 25\n",
    "# based on the frequency of the label (only consider the top no_jobs speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_jobs = train_data['job'].value_counts().reset_index()[:no_jobs].to_dict()['job']\n",
    "frequent_jobs = dict((v, k) for k, v in frequent_jobs.items())\n",
    "print(frequent_jobs)\n",
    "\n",
    "def convert_job_to_num(job):\n",
    "  # job not in the top jobs, assign it to the last category\n",
    "  other = no_jobs\n",
    "  if isinstance(job, str):\n",
    "    if job in frequent_jobs:\n",
    "      return frequent_jobs[job]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['job_id'] = train_data['job'].apply(convert_job_to_num)\n",
    "valid_data['job_id'] = valid_data['job'].apply(convert_job_to_num)\n",
    "test_data['job_id'] = test_data['job'].apply(convert_job_to_num)\n",
    "train_data['job_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'republican': 0, 'democrat': 1, 'none': 2, 'organization': 3, 'independent': 4, 'newsmaker': 5, 'libertarian': 6, 'activist': 7, 'journalist': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "party_id\n",
       "0    4497\n",
       "1    3336\n",
       "2    1744\n",
       "3     219\n",
       "4     147\n",
       "9     124\n",
       "5      56\n",
       "6      40\n",
       "7      39\n",
       "8      38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of top parties to consider a parameter\n",
    "no_party = 9\n",
    "# based on the frequency of the label (only consider the top no_party speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_party = train_data['party'].value_counts().reset_index()[:no_party].to_dict()['party']\n",
    "frequent_party = dict((v, k) for k, v in frequent_party.items())\n",
    "print(frequent_party)\n",
    "\n",
    "def convert_party_to_num(party):\n",
    "  # party not in the top parties, assign it to the last category\n",
    "  other = no_party\n",
    "  if isinstance(party, str):\n",
    "    if party in frequent_party:\n",
    "      return frequent_party[party]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['party_id'] = train_data['party'].apply(convert_party_to_num)\n",
    "valid_data['party_id'] = valid_data['party'].apply(convert_party_to_num)\n",
    "test_data['party_id'] = test_data['party'].apply(convert_party_to_num)\n",
    "train_data['party_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Texas': 0, 'Florida': 1, 'Wisconsin': 2, 'New York': 3, 'Illinois': 4, 'Ohio': 5, 'Georgia': 6, 'Virginia': 7, 'Rhode Island': 8, 'New Jersey': 9, 'Oregon': 10, 'Massachusetts': 11, 'Arizona': 12, 'California': 13, 'Washington, D.C.': 14, 'Vermont': 15, 'Pennsylvania': 16, 'New Hampshire': 17, 'Arkansas': 18, 'Tennessee': 19, 'Kentucky': 20, 'Maryland': 21, 'Delaware': 22, 'Alaska': 23, 'Minnesota': 24, 'North Carolina': 25, 'Nevada': 26, 'Indiana': 27, 'Missouri': 28, 'New Mexico': 29}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state_id\n",
       "30    2539\n",
       "0     1009\n",
       "1      997\n",
       "2      713\n",
       "3      657\n",
       "4      556\n",
       "5      447\n",
       "6      426\n",
       "7      407\n",
       "8      369\n",
       "9      241\n",
       "10     239\n",
       "11     206\n",
       "12     182\n",
       "13     159\n",
       "14     120\n",
       "15      98\n",
       "16      90\n",
       "17      86\n",
       "18      84\n",
       "19      75\n",
       "20      74\n",
       "21      69\n",
       "22      68\n",
       "23      65\n",
       "24      56\n",
       "25      56\n",
       "26      48\n",
       "27      38\n",
       "28      36\n",
       "29      30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of top states to consider a parameter\n",
    "no_state = 30\n",
    "# based on the frequency of the label (only consider the top no_state speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_state = train_data['state'].value_counts().reset_index()[:no_state].to_dict()['state']\n",
    "frequent_state = dict((v, k) for k, v in frequent_state.items())\n",
    "print(frequent_state)\n",
    "\n",
    "def convert_state_to_num(state):\n",
    "  # state not in the top states, assign it to the last category\n",
    "  other = no_state\n",
    "  if isinstance(state, str):\n",
    "    if state in frequent_state:\n",
    "      return frequent_state[state]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['state_id'] = train_data['state'].apply(convert_state_to_num)\n",
    "valid_data['state_id'] = valid_data['state'].apply(convert_state_to_num)\n",
    "test_data['state_id'] = test_data['state'].apply(convert_state_to_num)\n",
    "train_data['state_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'health-care': 0, 'taxes': 1, 'immigration': 2, 'elections': 3, 'education': 4, 'candidates-biography': 5, 'economy': 6, 'guns': 7, 'economy,jobs': 8, 'federal-budget': 9, 'jobs': 10, 'energy': 11, 'abortion': 12, 'foreign-policy': 13, 'state-budget': 14, 'education,state-budget': 15, 'transportation': 16, 'crime': 17, 'ethics': 18, 'iraq': 19, 'campaign-finance': 20, 'terrorism': 21, 'environment': 22, 'history': 23, 'job-accomplishments': 24, 'legal-issues': 25, 'social-security': 26, 'deficit,federal-budget': 27, 'state-budget,taxes': 28, 'energy,environment': 29}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subject_id\n",
       "30    6910\n",
       "0      381\n",
       "1      308\n",
       "2      253\n",
       "3      252\n",
       "4      237\n",
       "5      190\n",
       "6      137\n",
       "7      130\n",
       "8      125\n",
       "9      121\n",
       "10      98\n",
       "11      94\n",
       "12      92\n",
       "13      85\n",
       "14      75\n",
       "15      69\n",
       "16      64\n",
       "17      59\n",
       "18      58\n",
       "19      55\n",
       "20      53\n",
       "21      53\n",
       "22      52\n",
       "24      45\n",
       "23      45\n",
       "25      42\n",
       "27      40\n",
       "26      40\n",
       "28      39\n",
       "29      38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of top subjects to consider a parameter\n",
    "no_subject = 30\n",
    "# based on the frequency of the label (only consider the top no_subject speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_subject = train_data['subject'].value_counts().reset_index()[:no_subject].to_dict()['subject']\n",
    "frequent_subject = dict((v, k) for k, v in frequent_subject.items())\n",
    "print(frequent_subject)\n",
    "\n",
    "def convert_subject_to_num(subject):\n",
    "  # subject not in the top subjects, assign it to the last category\n",
    "  other = no_subject\n",
    "  if isinstance(subject, str):\n",
    "    if subject in frequent_subject:\n",
    "      return frequent_subject[subject]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['subject_id'] = train_data['subject'].apply(convert_subject_to_num)\n",
    "valid_data['subject_id'] = valid_data['subject'].apply(convert_subject_to_num)\n",
    "test_data['subject_id'] = test_data['subject'].apply(convert_subject_to_num)\n",
    "train_data['subject_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take number of top venues to consider a parameter\n",
    "no_venue = 30\n",
    "# based on the frequency of the label (only consider the top no_venue speakers as relevent, after 20, rest have less than 50 data points, not relevent)\n",
    "frequent_venue = train_data['venue'].value_counts().reset_index()[:no_venue].to_dict()['venue']\n",
    "frequent_venue = dict((v, k) for k, v in frequent_venue.items())\n",
    "print(frequent_venue)\n",
    "\n",
    "def convert_venue_to_num(venue):\n",
    "  # venue not in the top venues, assign it to the last category\n",
    "  other = no_venue\n",
    "  if isinstance(venue, str):\n",
    "    if venue in frequent_venue:\n",
    "      return frequent_venue[venue]\n",
    "    else:\n",
    "      return other\n",
    "  else:\n",
    "    return other\n",
    "\n",
    "train_data['venue_id'] = train_data['venue'].apply(convert_venue_to_num)\n",
    "valid_data['venue_id'] = valid_data['venue'].apply(convert_venue_to_num)\n",
    "test_data['venue_id'] = test_data['venue'].apply(convert_venue_to_num)\n",
    "train_data['venue_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
